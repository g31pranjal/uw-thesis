\chapter{Conclusion and Future Work}
\label{c:conclusion-future-work}

Column-oriented RDBMSs are read-optimized analytical systems that have introduced several storage and query processing techniques to improve the scalability and performances of RDBMSs. We studied the integration of these techniques into \gls{gdbms}s, which are also read-optimized analytical systems. Although some of these techniques can directly be applied to \gls{gdbms}s, there are significant differences between the data and query workloads that column-oriented \gls{rdbms}s and \gls{gdbms}s support, which require adapting some of these techniques. We first outlined a set of guidelines for designing the physical storage layer and query processor of \gls{gdbms}s, from which we derived a set of desiderata. At the core of these guidelines is the observation that graph data is not completely unstructured and there is a pattern to how this data is accessed during query processing. In fact, there exists different types of structures in a graph, that constitutes a soft schema, that every graph data adheres to. Specifically edges are read in the order they appear adjacency lists, access to neighbour properties or node properties cannot be localized, and any compression technique that is used should require constant-time operations to access and decompress arbitrary locations in columns. These guidelines and the different types of structures we observed in graph-structured data instructed our design of columnar structures, null compression scheme, and list-based processor. We demonstrated that our storage techniques has increased the scalability of GraphflowDB by 3.55x and often with non-trivial performance benefits (even for null compression when the columns are sparse enough) and our list-based processor has increased the performance by up to 1.6x in our micro-benchmarks. 

%We demonstrated that our techniques 

%We first identified a set of guidelines for designing the physical storage layer and query processor of GDBMdescribed how to redesign these techniques, specifically new edge and vertex ID schemes to obtain positional offset and sequentiality, null suppression schemes, and vector-based processing, to increase the scalability and performance of \gls{gdbms}s. We

% an already existing set of work to a new setting. We show that the conventional techniques used in column-oriented \gls{rdbms} cannot be passed on to a \gls{gdbms} directly and hence, we redesign them to suit our requirements. 

%At the core of our work is the fact that graph data is not completely unstructured and that this data is accessed in definite patterns during a graph query processing. In fact, there exists different types of structures in a graph, that constitutes a soft schema, that every graph data adheres to. In this thesis, we propose efficient columnar data structures and powerful optimizations that compacts the in-memory storage of property graph data by exploiting this structure in graph data. Our columnar data structures stores data closely-packaged and provides efficient constant-time random access with decoding, which is an essential requirement in the context of \gls{gdbms}. Moreover, we order the data, in adjacency lists and single-directional property pages, in a way that helps achieve cache locality wherever possible. We also introduce list-based query processing to execute queries, which is a mix of traditional volcano-styled processing, that is prevalent in \gls{gdbms}, and vectorized processing, which is used in column stores. The list-based processing adds operators that operate on an entire adjacency list in a single execution thereby getting cache benefits from reading together from ordered placement of data.

%As graph data can be highly sparse and inconsistent, we compress our structures, to avoid keeping \texttt{NULL}s or empty adjacency lists, using the redesigned \texttt{NULL} compressing technique that allows for random look-ups on compressed data. Our repurposed \texttt{NULL} compression allows access times comparable to uncompressed case while still. We also achieve compression on adjacency lists by using a new vertex and edge ID scheme which we adopt for simplifying property look-ups. Our new ID scheme can represent an edge and its neighbouring vertex in adjacency list by as less as 4 bytes.

We outline three immediate directions of future work:
\begin{itemize}
	\item \textbf{Optimizing unstructured graph data:} Noticeably left out from our work are techniques to optimize the storage of unstructured data that appears in some graph-structured datasets in real-world. A common approach to storing such data is to keep them in variable-width records and structures like linked-lists, which can be seen as a type of row-oriented storage. However, such a storage requires decoding or is distributed randomly in memory, respectively. An important line of future work is to research efficient data structures that makes accessing and compressing unstructured data more efficient. Compression schemes often exploit structure, so the lack of structure for this data makes this line of work very challenging. %Most of the existing \gls{gdbms} follows a close approach by assuming the data has not structure at all. Though difficult, a possible line of future work can be to research efficient data structures that makes maintenance and accessing of unstructured data more efficient. 
	
	\item \textbf{Factorized processing:} Another interesting extension is to study adopting factorized processing in the context of \gls{gdbms}. Our current list-based processing is a simple and limited form of factorized processing which is limited in capability, i.e, it can only generate plans that has \texttt{LIST JOIN} only if no further \texttt{JOIN} operator depends on it. A complete factorized query processor could perform \texttt{LIST JOIN}s at all levels and also produce more succinct outputs of the query.
	
	\item \textbf{Comparison against other systems: }An interesting evaluation that we left out is to compare GraphflowDB, with our columnar data structures and techniques, to existing \gls{gdbms}s on a common workload from a popular benchmark, such as \gls{ldbc}. This will test the overall efficiency in storage and performance of our changes on more practical queries. Comparisons against column-oriented \gls{rdbms}s, such as MonetDB~\cite{monet-2decades}, DuckDB~\cite{duckdb}, would also provide another point of comparison for our list-based processing technique against the vector-based processing that these systems use. 
	
\end{itemize}


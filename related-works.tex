\chapter{Related Works}
\label{c:related-works}

In this chapter, we review various works that are relevant to our current work that lies at the intersection of columnar storage and compression, graph compressing, and graph query processing. Section~\ref{graph-compression} discusses works in representing graphs and graph databases over time for a variety of use cases. Section~\ref{}

\section{Storage of Graphs and Graph Databases}
\label{graph-compression}

Over the years, storage and compact representation of graph has remained a trivial problem to solve. As the importance of graph as a viable data model has evolved over time, from network data model to web graph, then RDF data and finally into property graph, new solutions for compressing have sprung up. The earliest solutions aimed at optimizing for a particular application or set of algorithms. For instance, Reference~\cite{compress-transitive-closure} stored transitive closure of the graph for reachibility queries, \cite{Claude2010} stored the graph along with its transpose for supporting reverse queries, whereas \cite{compress-nbr-q} optimized for queries computing neighbours of a vertex in graph. Certain solutions even transform the graph into alternate representation. Reference \cite{feder} represents graph as bi-partite cliques and compresses them with the aim of optimizing for common algorithms like vertex connectivity and shortest paths, while \cite{graph-summ} represent graphs as aggregate graphs with corrections. On the contrary, our work is a general solution to optimize the storage of property graphs, that has properties over vertices and edges, and vast list of graph algorithms and queries over input graph.

Perhaps more relevant to our work is storage and comression of web data that consists of URLs and links. Adler and Mitzenmacher in \cite{adler} use Huffman encoding to encode vertices in the graph and represent adjacency lists of certain vertices by referencing to the adjacency lists of other vertex with similar links. Completely orthogonal approach is described in \cite{suel} which avails prorperties of web graph to store data in a storage efficient manner. However, we do not optimize our system for specific type of graph; rather we base our solution on general characteristics of graph data.

Yet another set of works involves RDF data. Approach followed by \cite{comp-rdf, rbcomp, hdt} to represent RDF data compactly make use of the underlying structural patterns to formulate set of rules that encodes multiple entities together. Another approach (graph-based) aims at optimizing the topology of RDF data \cite{k2triples, ik2trees} by representing it in data-structures that are derived from widely-used k2-trees \cite{k2trees} that represents adjacency matrix as trees that are essentially NULL pruned. Our work too emphasises on using structure in graph data but at the same time aims at improving query performance with a more succinct representation of data in memory. We discuss columnar data-structures for RDF data in Section~\ref{column-storage}.

Among \gls{gdbms}s, many solutions use a set of relational tables to store the graph data \cite{hana-graph, oracle}, which is prohibitive. Among those that have a native storage, Neo4j \cite{neo4j} and JanusGraph \cite{janusgraph} both stores edges in adjacency lists that is partitioned by edge labels. While in Neo4j, properties are stored in doubly linked-list with one node for each property, JanusGraph store properties in records as a sequence of key-value pairs. on the other hand, DGraph \cite{dgraph} utlizes key-value store to hold adjacency lists as well as properties. Reference \cite{compact-rep-graph} is the only academic work we are aware of that talks about the representation of property graph data. It stores adjacency lists as k2-trees, while properties are represented either as lists or in k2-trees depending on the number of unique values. While we store graph topology as edge-partitioned adjacency lists, our solution for properties is to have a column per property. Our edge and vertex columnar structure differd from that in \cite{compact-rep-graph} in two ways; 1) we use positional offsets to access property values, and 2) we arrange edge properties into pages to get sequential access.

\section{Columnar Storage and Compression}
\label{column-storage}

As reviewed, columnar storage is preffered over row-based storage in \gls{gdbms} where the workload in predominantly analytical. Column stores are known to have their own set of optimizations and processing techniques that makes it highly efficient in storage and processing, like block processing, compression etc. \cite{col-vs-row, design-imp-book}. C-Store \cite{c-store} is an updatable column storage system that keeps multiple copies of columns sorted differently and uses positional offsets in a column to process data. Building on it, \cite{abadi-col-comp, abadi-sparse-col} talks about light-weight compression and execution over compressed data in C-Store. MonetDB \cite{monet-2decades} assumes similar vertical partitioning into columns \texttt{(BAT)} but follows a different execution stratetegy by means of binary opeations on BAT. MonetDB benefits from tight for-loops and bulk processing that give then good cache locality and avoids instruction misses. Even though our idea of vertical partitioning is in line with these works, our solution is native for \gls{gdbms} and hence organizes and executes process differently.

Attempts have also been made to store RDF data in columns. Reference \cite{rdf-vertical} is a direct application of C-store to store RDF data as columnar data-structures. Each unique properties, in this solution, is stored as 2-column table and hence accessed efficiently. Even though this is technique provides fast property accessing, it doesn't optimizes the system for path queries \cite{rdf-vertical-critic}. Hexastore \cite{hexastore} takes the idea of vertical partitioning forward by defining a column for each RDF element and sorting it 2 possible ways. RDF-3x \cite{rdf-3x} uses a similar structure with delta encoding to build b+ indexes over each column. In our work, we do not maintain 6-way indexing structure, which forms the core of \cite{hexastore, rdf-3x}; instead lookups happen using traditional adjacency lists. Like \cite{rdf-vertical}, the properties in our solution is stored in columns, however, they are ordered in case of edge property columns. 

Among \gls{gdbms}, JanusGraph is the only system we are aware of that uses variable-length encoding. On the other hand, we use fixed-length encoding besides other techniques to reduce the size of representation of edges and vertices in adjacency lists.

\section{Query Processing}

Volcano-styled query processing \cite{volcano} 







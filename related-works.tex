\chapter{Related Work}
\label{c:related-works}

This thesis studied the integration of columnar storage and query processing techniques to GDBMSs. We review related work on column-oriented relational systems and other storage and compression techniques that have been designed for GDBMSs and RDF engines. There is an extensive literature on different storage and compression techniques designed for specific graphs, which we do not cover here. We refer the interested readers to reference \cite{Survey and Taxonomy of Lossless Graph Compression
and Space-Efficient Graph Representations} for a survey on the lossless compression techniques from literature. These techniques focus on compressing the topology of the graph and broadly can achieving high compression rates for special types of graphs, e.g., Erd\H{o}s R\'enyi graphs or web graphs, but require decompression while accessing adjacencies. Therefore they are less applicable for an in-memory GDBMS that the techniques we considered in this thesis.

% on columnar storage and compression for GDBMSs and graph query processing. Section~\ref{graph-compression} discusses works in representing graphs and graph databases for a number of use cases. Section~\ref{column-storage} talks about existing solutions employing columnar storage and compression in \gls{rdbms} and RDF databaes. 

\section{Storage and Compression Techniques in Column-Oriented Relational Systems}
\label{sec:column-stores-overview}

Column-oriented RDBMSs are designed primarily for OLAP applications that are analytics heavy that perform aggregations over entire tables or subsets of tuples. At a high-level these systems store the relations in disk pages as a set of separate columns, instead of a set of rows. The column $c$ value of a particular row $r$ can be found using a positional offset, using the row ID of $r$, in the page that stores column $c$. The row IDs are referred to as surrogate keys. Prior to the emergence of column stores, such as C-Store~\cite{}, MonetDB~\cite{}, and VectorWise~\cite{},  prior work, such as PAX~\cite{}, had used columnar storage inside in the context of row-oriented systems. PAX was a storage design that stores have stores a set of rows in each disk page, but organizes the rows inside each page in a columnar format. 

Many prior work on column stores introduced a set of columnar storage, compression, and query processing techniques. These techniques include: positional offsets (also called virtual IDs) to directly access values in columns for different rows, columnar compression schemes, vector-oriented query processing, late materialization, and direct operation on compressed data among others. A detailed survey of these techniques can be found in reference~\cite{abadi-survey}, which reviews the techniques introduced in C-Store, MonetDB, and VectorWise.  This thesis studied how to directly integrate these techniques to in-memory GDBMSs or modify and adapt them so that they can be integrated into in-memory GDBMSs. The most relevant techniques that we identified and integrated are:  (i) a set of columnar storage structures to store different components of property graphs (shown in Table~\ref{}); (ii) vertex and edge ID schemes that allow direct positional offsets into these columns; (iii) compression schemes that include dictionary encoding, zero suppression, compressed edge and vertex IDs, and a null and empty-list compression scheme;  and (iv) list-based processing which is a hybrid between Volcano-style and vector-oriented processing. 

For disk-based GDBMSs, other techniques, in particular other compression schemes, such as run-length encoding to compress vertex and edge properties, or integer compression schemes from reference~\cite{lemire} to compress adjacency lists might also be beneficial. For an in-memory systems these techniques can increase the systems scalability but they will also decrease performance as data needs to be decompressed before accessing. Except for null-compression, our other compression schemes do not decrease an in-memory GDBMS's performance as they do not require decompression. Null compression slows down compression but not significantly, so offers a good performance and space tradeoff. Whether or not GDBMS-specific versions of other compression schemes can be developed for in-memory GDBMSs is an interesting research direction.

% are known to have their own set of optimizations and processing techniques that makes it highly efficient in storage and processing, like block processing, compression etc. \cite{col-vs-row, design-imp-book}. C-Store \cite{c-store} is an updatable column storage system that keeps multiple copies of columns sorted differently and uses positional offsets in a column to process data. Building on it, \cite{abadi-col-comp, abadi-sparse-col} talks about light-weight compression and execution over compressed data in C-Store. MonetDB \cite{monet-2decades} assumes similar vertical partitioning into columns \texttt{(BAT)} but follows a different execution stratetegy by means of binary opeations on BAT. MonetDB benefits from tight for-loops and bulk processing that give then good cache locality and avoids instruction misses. Even though our idea of vertical partitioning is in line with these works, our solution is native for \gls{gdbms} and hence organizes and executes process differently.

\section{Storage and Compression for GDBMSs and RDF Systems}
\label{sec:gdbms-storage-and-compression}

There are several existing native GDBMSs, whose internals have been described in technical papers or documents. These systems adopt a columnar structure only for storing the topology of the graph. This is done either by using a variant of vanilla adjacency list format or CSR. These systems use other row-oriented structures, such as property stores that store a sequence of key-value properties, or a separate key-value store to store vertex and edge properties. 
For example, Neo4j~\cite{neo4j} stores the topology of the graph in adjacency lists that are partitioned by edge types and stored in linked-lists, where each edge record points to another edge record that is not necessarily stored consecutively in disk. Similarly, the property of each vertex and edge are stored in a linked-list in an unstructured manner, where each property record points to the next property record and encodes both the key, data type, and value of the property. This can be seen as adopting a row-oriented storage for properties. Similarly, JanusGraph \cite{janusgraph} stores its edges in adjacency lists partitioned by edge labels and properties as a consecutive  key-value pairs (so in row-oriented format) \todo{Is this accurate?}. JanusGraph uses variable- length encoding when storing X \todo{Complete}. Instead, we use fixed-length encodings in our compression schemes. DGraph~\cite{dgraph} uses 
key-value store to hold adjacency lists as well as properties.  We are unaware of any compression schemes adopted by Neo4j and DGraph. All of the above native GDBMSs adopt Volcano-style processors. In contrast, our design adopts columnar structures for vertex and edge properties and a list-based processor. Our storage techniques and list-based processing allows our system to benefit more from data locality. In addition we improve on these designs by more compressed edge and vertex ID storages (these systems use 8 bytes for each ID) and null compression.

There are also several GDBMSs that are developed directly on top of an RDBMS or another database system. For example Oracle Spatial and Graph~\cite{oracle-spatial-and-graph} supports a property graph model using the PGQL language~\cite{pgql} that is built on top of Oracle database. SAP's graph database~\cite{sap-graph-story} is developed on top of HANA. These systems can benefit from the columnar techniques provided by the underlying RDBMS but the underlying RDBMS techniques are not optimized for graph storage and queries. For example, SAP's graph engine uses SAP HANA's columnar-storage to store vertex and edge tables but these columns do not have CSR-like structures for indexing edges of each vertex. Similarly existing RDBMSs do not implement null compression schemes similar to our prefix-sum-based scheme that allow constant-time access to arbitrary column values.

RedisGraph~\cite{redisgraph} is a system that stores its adjacency lists and properties inside the Redis~\cite{redis} distributed in-memory key value database (though RedisGraph's latest release we are aware of runs only in single nodes).  
RedisGraph has a query processor that is based on performing linear algebra operations. The system converts Cypher queries into a sequence of linear-algebra based operators, which are executed using the GraphBLAS~\cite{} linear algebra library. This can be seen as performing column-oriented processing, as entire columns, which are stored in  are processed during query evaluation. We have not benchmarked our system against RedisGraph to evaluate the efficiency of this approach. This is an interesting direction we have left for future work.

ZipG~\cite{ZipG: A Memory-efficient Graph Store
for Interactive Queries} is a distributed compressed storage engine for property graphs that can answer queries to retrieve adjacencies as well as vertex and edge properties. ZipG is based on a compressed data structure called Succinct~\cite{Succinct: Enabling Queries on Compressed Data}. Succinct stores semi-structured data that is encoded as a set of key and list of values. For example, a node $v$'s properties can be stored as the $v$'s ID as the key and a list of values, corresponding to each property. The properties are distinguished through special delimiter characters ZipG maintains. Edge properties and adjacency lists can be encoded in a similar fashion. All of this data is encoded in flat files in a sorted manner by keys. Succinct then compresses these files using suffix arrays and several secondary level indices based on taking samples of key-value properties to access different records. Although the authors report achieving good compression rate, unlike our structures, access to a particular record is not constant time and requires accessing secondary indexes followed by a binary search. Therefore, this type of compression provides slower access than our structures. 

Reference \cite{compact-rep-graph} describes a k2-tree-based adjacency lists storage, while properties are represented either as lists or in k2-trees depending on the number of unique values. Our columnar structures differ from that in \cite{compact-rep-graph} in two ways: (i) we use positional offsets to access property values; and (ii) we arrange edge properties into pages to get sequential access.

Several RDF systems also use columnar structures to store RDF databases, which consist of a set of (subject, predicate, object) triples. Reference \cite{rdf-vertical}
stores a set of \emph{property tables}, which store a set of (subject, object) pairs for each unique predicate. This is similar to partitioning the edges based on their types in property graphs. The property tables are partitioned and stored as 2 columns. However, this storage is not as optimized as the standard storages in GDBMSs, e.g., the edges of a particular object is not stored in native CSR or adjacency list format. \todo{Is this coverage accurate? If not, what's columnar about reference~\cite{rdf-vertical}?} Hexastore \cite{hexastore} improves on the idea of predicate partitioning by defining a column for each RDF element \todo{What's an element?} and sorting the column in 2 possible ways in B+ trees. This is similar but not as efficient as double indexing of adjacency lists in GDBMSs \todo{Is this accurate?}. RDF-3X \cite{rdf-3x} is an RDF system that stores a large triple table that is indexed in 6 B+ tree indexes over each column. Similarly, this storage is not as optimized as the native graph storages found in GDBMSs.

Another set of approaches \cite{comp-rdf, rbcomp, hdt} to represent RDF data compactly make use of the underlying structural patterns to formulate set of rules that encodes multiple entities together. Another approach (graph-based) aims at optimizing the topology of RDF data \cite{k2triples, ik2trees} by representing it in data-structures that are derived from widely-used k2-trees \cite{k2trees} that represents adjacency matrix as trees that are essentially NULL pruned. Our work too emphasizes on using structure in graph data but at the same time aims at improving query performance with a more succinct representation of data in memory.  \todo{I don't fully understand this. Rewrite this making it similar to how I am covering related work.}

Finally, several prior work has introduced novel storage techniques for storing graphs in GDBMSs or analytics systems. These works primarily focus on storing the topology of the graph and adopt variants of CSR format~\cite{yale}. LLAMA is a data structure based on CSR for storing adjacency lists for a write-heavy system. The data structure is designed to provide multi-version support when applications require accessing different versions of adjacency lists. Our focus in this thesis is read heavy queries and our data structures are not optimized for write-heavy workloads. Similarly STINGER~\cite{stinger} is a system that describes a data structure to store the topology of a graph also under write-heavy workloads . At a high-level the data structure adopts a vanilla adjacency list format that is divided by different edge types, where each list  is accessible using vertex IDs. Lists are stored in a linked list of blocks that allow very fast updates in a shared memory system. DISTINGER~\cite{distinger} adopts STINGER's structure to a distributed setting. These techniques are complementary to our work and our edgeID and vertex ID schemes and columnar structures for storing the graph topology can be integrated into these structures to benefit from their functionalities, such as multi-version support. 


%In our work, we do not maintain 6-way indexing structure, which forms the core of \cite{hexastore, rdf-3x}; instead lookups happen using traditional adjacency lists. Like \cite{rdf-vertical}, the properties in our solution is stored in columns, however, they are ordered in case of edge property columns. 

% in our setting as variable-length encodings can decrease the performance of in-memory systems significantly.

%\section{Other Work on Storage and Compression for Graph Structured Data}
%\label{sec:gdbms-storage-and-compression}


 
%Over the years, storage and compact representation of graph has remained a trivial problem to solve. As the importance of graph as a viable data model has evolved over time, from network data model to web graph, then RDF data and finally into property graph, new solutions for compressing have sprung up. The earliest solutions aimed at optimizing for a particular application or set of algorithms. For instance, Reference~\cite{compress-transitive-closure} stored transitive closure of the graph for reachibility queries, \cite{Claude2010} stored the graph along with its transpose for supporting reverse queries, whereas \cite{compress-nbr-q} optimized for queries computing neighbours of a vertex in graph. Certain solutions even transform the graph into alternate representation. Reference \cite{feder} represents graph as bi-partite cliques and compresses them with the aim of optimizing for common algorithms like vertex connectivity and shortest paths, while \cite{graph-summ} represent graphs as aggregate graphs with corrections. On the contrary, our work is a general solution to optimize the storage of property graphs, that has properties over vertices and edges, and vast list of graph algorithms and queries over input graph.
%
%Perhaps more relevant to our work is storage and comression of web data that consists of URLs and links. Adler and Mitzenmacher in \cite{adler} use Huffman encoding to encode vertices in the graph and represent adjacency lists of certain vertices by referencing to the adjacency lists of other vertex with similar links. Completely orthogonal approach is described in \cite{suel} which avails prorperties of web graph to store data in a storage efficient manner. However, we do not optimize our system for specific type of graph; rather we base our solution on general characteristics of graph data.





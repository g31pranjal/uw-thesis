
\chapter{Introduction}
\label{introduction}

The term \gls{gdbms} in its contemporary usage refers to data management software, such as Neo4j \cite{neo4j}, JanusGraph~\cite{janusgraph}, TigerGraph~\cite{tigergraph}, and GraphflowDB~\cite{kankanamge:graphflow, mhedhbi:sqs}, that adopt the property graph data model~\cite{neo4j-property-graph-model}. In this model, application data is represented as a set of vertices, which represent the entities in the application, directed edges, which represent the relationships between entities, and arbitrary key-value properties on the vertices and edges, where both the relationships and key-value properties can depict different levels of structure.

\gls{gdbms}s have lately gained popularity among a wide range of analytics applications, such as fraud detection and risk assessment in financial services to recommendations in e-commerce and social networks~\cite{sahu:survey}. These applications have read-heavy workloads that search for patterns in a graph-structured database, which often requires processing large amounts of data. In the context of \gls{rdbms}, column-oriented storage ({\em column stores})~\cite{c-store, monetdb, boncz-vectorwise, oracle-col} employ a set of storage, indexing, and query processing techniques to support traditional read-heavy analytics applications, such as business intelligence and reporting, that also process large amounts of data. As such, these columnar techniques are relevant for improving the performance and scalability of \gls{gdbms}s. In this thesis, we revisit columnar storage and query processing techniques and investigate their integration in \gls{gdbms}s. Specifically, we discuss the applicability of columnar storage techniques, compression schemes for columns~\cite{abadi-col-comp, abadi-sparse-col, boncz-comp}, and block-oriented query processing~\cite{boncz-monet-vectorized, col-vs-row}, for storing and accessing different components of GDBMSs. Even though analytical workloads that are run on \gls{gdbms}s and those on column-oriented \gls{rdbms} exhibit many similarities, they have different fundamental data access patterns. This calls for redesigning columnar techniques in the context of \gls{gdbms}.

We begin with a deep analysis of general query execution on graph data to get a low-level knowledge of patterns in data access. On the other hand, we also identify different levels of structures that can be present in graph data. The idea is to utilize our understanding to influence our decisions while redesigning the physical data layout and compressing and processing techniques. 

To implement the column store, we first identify the cases where columnar storage can be directly integrated into \gls{gdbms}. For instance, columnar storage is directly applicable to storing vertex properties. Similarly, the popular compressed sparse row (CSR) or column (CSC) formats to store the topology of graphs, i.e., the edges between vertices, are columnar data structures that employ a variant of run-length encoding. Contrary to vertex properties, applying columnar storage for storing edge properties in a naive manner leads to a sub-optimal solution which is not efficient in retrieval. We show the inefficiency of using straightforward positional edge IDs to access edge properties from columns and hence, redesign storage for edge properties in the context of GDBMSs. We follow a similar approach to evaluate the applicability of columnar compression techniques as well as query processing in \gls{gdbms} with columnar storage. For each, we review the approaches that exist and identify their shortcomings for our use case. Finally, we present our redesigned solution. 

\section{Contributions}

The specific contributions of this thesis are as follows:

\begin{itemize}
	\item \textbf{Guidlines and Desiderata:} In Chapter~\ref{c:guidelines}, we begin by reviewing the properties of data access patterns in GDBMSs, from which we derive a set of general guidelines and desiderata for designing the physical data layout of \gls{gdbms}s. We further explore the characteristics of real-world graph data and identify different types of structures that can exist in the graph data. The guidelines instruct where columnar techniques can be applied and some fundamental limitations about which type of data accesses can be localized in GDBMSs without data replication.
	
	\item \textbf{Columnar Storage:} In Chapter~\ref{c:columnar-storage}, we explore the application of columnar data structures for storing different
	components of \gls{gdbms}s. We start with components that can directly be stored in columnar structures, i.e., vertex properties and adjacency lists for many-to-many edges. Next, we identify the requirements from columnar data structures for edge properties and present two sub-optimal solutions that optimize storage and performance each. For each of the solution, we discuss their pros and cons. We then describe a third solution, \emph{single-directional property pages}, that sits in between the previously described 2s solutions and strikes a balance between storage and performance efficacy. Lastly, we show how single cardinality edges (having one-to-one, one-to-many and many-to-one edge labels) can be stored and referenced as the property of either source or destination vertex in vertex property columns. As we discuss in Chapter~\ref{c:evaluation}, storing these edges in vertex property columns can achieve huge storage and performance improvements.
	
	\item \textbf{New Vertex and Edge ID Scheme:} As a byproduct of switching to columns for storing properties, we introduced a new ID scheme for identifying vertex and edges in the system based on the positional offset of their properties. This allows for fast random access to properties in property columns. Besides, the new scheme present immense opportunities to represent edges and vertices compactly in adjacency lists. In particular, we decompose the IDs into several small components that can be factored out depending on the existence of different types of structure in data. For highly structured data, an edge and vertex together can be represented in adjacency list using a single value of a very small size. Our scheme, along with structural optimizations, can reduce the overhead of representing an edge and neighbour vertex by up to 3.5x to merely 6 bytes per edge.
	
	\item \textbf{Columnar Compression:} In Chapter~\ref{columnar-compression}, we discuss the application of existing columnar compression techniques in GDBMSs based on our guidelines. For each of the columnar techniques, we review its applicability and discuss where can they be applied in the columnar storage of \gls{gdbms}. Since a lot of property columns, as well as adjacent lists, can be sparse, we next review existing null compression techniques for columns. and their shortcomings and describe a new null compression scheme, based on storing prefix sums, that address these shortcomings. Our scheme allows constant-time access to any null or non-null property and requires 2 bits per stored element. We show that existing null compression schemes from column stores would lead to very slow access in the context of GDBMSs. Hence, we redesign a new GDBMS-specific version of null compression based on storing prefix sums, that address the shortcomings. Our scheme allows constant-time access to any null or non-null property and requires 2 bits per stored element. Our new null compression scheme is broadly applicable to compress both null vertex properties as well as empty adjacency lists.
	
	\item \textbf{List-based Processing:} In Chapter~\ref{list-based-processing}, we review the query processing techniques used in \gls{gdbms} as well as in column-oriented \gls{rdbms}. We show that the vector-styled~\cite{volcano} query processing does not benefit from the arrangement data in adjacency lists and single-directional property pages. On the other hand, column-at-a-time~\cite{col-vs-row} or vectorized~\cite{boncz-vectorwise1} query processors employed by several column stores do not adapt well to the scenario of graph queries that abundant join operations. To overcome the shortcomings, We introduce a new list-based query processor that processes the query per adjacency lists. Our new processor uses both volcano-style pipelining of operators, where single tuples are passed between operators, as well as vectorized processing, where blocks are variable-sized and based on the sizes of the lists that need to be processed.
\end{itemize}

We evaluate our work in Chapter~\ref{c:evaluation}. ...

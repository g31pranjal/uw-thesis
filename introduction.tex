
\chapter{Introduction}
\label{introduction}

The term \gls{gdbms} in its contemporary usage refers to data management software, such as Neo4j \cite{neo4j}, JanusGraph~\cite{janusgraph}, TigerGraph~\cite{tigergraph}, and GraphflowDB~\cite{kankanamge:graphflow, mhedhbi:sqs}, that adopt the property graph data model~\cite{neo4j-property-graph-model}. \gls{gdbms}s have lately gained popularity among a wide range of analytics applications, such as fraud detection and risk assessment in financial services to recommendations in e-commerce and social networks~\cite{sahu:survey}. These applications have read-heavy workloads that search for patterns in a graph-structured database, which often requires processing large amounts of data. In the context of \gls{rdbms}, column-oriented storage ({\em column stores})~\cite{c-store, monetdb, vectorwise, oracle, ziauddin:zone-maps, ms} employ a set of storage, indexing, and query processing techniques to support traditional read-heavy analytics applications, such as business intelligence and reporting, that also process large amounts of data. As such, these columnar techniques are relevant for improving the performance and scalability of Gs.

In this theis, we revisit several columnar storage and query processing techniques and investigate their integration into GDBMSs. Specifically, we discuss the applicability of columnar storage techniques, compression schemes for columns~\cite{}, block-oriented query processing~\cite{}, and zone maps~\cite{}, for storing and accessing different components of GDBMSs. 

We first identify the cases when GDBMS can directly integrate these techniques. For example, columnar storage is directly applicable for storing vertex properties. Similarly, the popular compressed sparse row (CSR) or column (CSC) formats to store the topology of the graphs, i.e., the edges between vertices, are columnar data structures that employ a variant of run-length encoding compression scheme. We then identify the cases when there are significant differences between column stores and GDBMSs that require redesigning some these techniques in the context of GDBMSs. For example, we show the inefficiency of using straightforward positional edge IDs and using columns for edge properties in the context of GDBMSs. Similarly, we show that existing null compression schemes from column stores would lead to very slow access in the context of GDBMSs. We then redesign new GDBMS-specific versions of these techniques. For example, we describe a new prefix-sum based null compression scheme, which is broadly applicable to suppress both null vertex properties as well as empty adjacency lists. After appropriate redesigning, we show that these techniques can significantly improve both the scalability and the performance of GDBMSs.

\section{Contributions of the thesis}

The specific contributions of this paper are as follows:

\begin{itemize}
	\item {\bf General Guidelines:} We begin by overviewing the properties of data access patterns in GDBMSs, from which we derive a set of general guidelines for designing the physical data layout of \gls{gdbms}s. These guidelines instruct where columnar techniques are possible to use and some fundamental limitations about which type of data accesses can be localized in GDBMSs without data replication.
	
	
	
	\item {\bf Columnar Storage:} In Section~\ref{sec:columnar-storage}, we explore  the application of columnar data structures for storing different components of the databases of GDBMSs. We start with components that can directly be stored in columnar structures, such as vertex properties, and one-to and many-to-many edges. We then discuss how to use columnar structures for edge properties, which requires designing positional edge IDs. We start by discussing two natural edge ID schemes and their corresponding columnar structures and discuss their shortcomings. We then describe a new scheme we call {\em page-level positional IDs} and its corresponding {\em vertex-group CSR structure} which addresses these shortcomings. We end this section with a decision tree for deciding which columnar structures are suitable for storing edges and edge properties.  
	\item {\bf Columnar Compression:} In Section~\ref{sec:columnar-compression}, we discuss the application of columnar compression techniques in GDBMSs. We start by reviewing directly applicable compression techniques. We then review existing null compression techniques and their shortcomings and describe a new null compression scheme, based on storing prefix sums, that address these shortcomings. Our scheme allows constant time access to any null or non-null property and requires 2 bits per stored element. Finally, we describe the application of using run-length encoding for storing the page-level positional edge IDs we describe in Section~\ref{sec:columnar-storage}. 
	\item {\bf List-oriented Processing:} In Section~\ref{sec:list-oriented-processing}, we review block- or vector-oriented query processors employed by several column stores and discuss their shortcoming in the context of GDBMSs. We then introduce a new list-based block-oriented query processor, which uses both Volcano-style processing, where single tuples are passed between operators, as well as block-oriented processing, where blocks are variable size and based on the sizes of the lists that need to be processed. 
	
	\item {\bf List-based Zone Maps:} In Section~\ref{sec:list-maps}, we revisit the zone-map~\cite{} indexes that  is employed in some column stores. Zone maps store aggregates, such as min, sum, or max, on each page of a column, which are used by the system for both pruning the page when queries have predicates or performing an aggregate. We discuss the limitation of this approach in the context of GDBMSs, and adapt it to GDBMSs by defining list-based zone maps, which store these aggregates per list.
	
	\item Section~\ref{sec:evaluations} presents our evaluations. We show that integrating these columnar techniques into an in-memory GDBMS increases the systems' scalability by Xx and performance by Yx. We also show that our GDBMS-specific techniques outperform traditional columnar techniques significantly on micro-benchmarks as well as the popular LDBC bechnmark.
	
	\item Finally, Sections~\ref{sec:rw} and~\ref{sec:conclusions}, respectively, review related work and conclude.   
\end{itemize}
